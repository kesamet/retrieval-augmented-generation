USE_TRACING: False

DEVICE: cpu  # used only by embeddings and propositionizer

TEXT_SPLIT_MODE: default  # default or propositionize
# propositionize uses propositionizer model

# MODELS_DIR: ./models
MODELS_DIR: /Users/user/Desktop/Dvorak/Work/models

EMBEDDINGS_PATH: bge-small-en-v1.5
# EMBEDDINGS_PATH: all-mpnet-base-v2
# EMBEDDINGS_PATH: all-MiniLM-L6-v2

VECTORDB_TYPE: faiss
VECTORDB:
  - PATH: ./vectordb/faiss
    NAME: document
    DESCRIPTION: A tool useful for when you need to answer questions about the source document. Input should be a search query.


# TODO: OLMoE does not seem to work on ollama
# LLM_TYPE: gguf
# LLM_PATH: olmoe-1b-7b-0924-instruct-q4_k_m.gguf
# PROMPT_TYPE: olmoe

# LLM_TYPE: groq
# LLM_PATH: mixtral-8x7b-32768
# PROMPT_TYPE: mistral

LLM_TYPE: ollama
LLM_PATH: mymodel
PROMPT_TYPE: llama3

# LLM_TYPE: gemini
# LLM_PATH: gemini-1.5-flash
# PROMPT_TYPE: gemini

LLM_CONFIG:
  MAX_NEW_TOKENS: 512
  TEMPERATURE: 0.2
  REPETITION_PENALTY: 1.1
  CONTEXT_LENGTH: 4000

BASE_RETRIEVER_CONFIG:
  SEARCH_K: 4

# RERANKER_PATH: tart-full-flan-t5-xl
# RERANKER_TYPE: tart
RERANKER_PATH: bge-reranker-base
RERANKER_TYPE: bge

RERANK_RETRIEVER_CONFIG:
  SEARCH_K: 10
  TOP_N: 4

COMPRESSION_RETRIEVER_CONFIG:
  SEARCH_K: 10
  SIMILARITY_THRESHOLD: 0.5

PROPOSITIONIZER_PATH: propositionizer-wiki-flan-t5-large
PROPOSITIONIZER_CONFIG:
  CHUNK_SIZE: 1000
  CHUNK_OVERLAP: 0
