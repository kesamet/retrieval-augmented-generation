DEVICE: cpu

TEXT_SPLIT_MODE: default  # default or propositionize
# propositionize uses propositionizer model

MODELS_DIR: ./models

# EMBEDDINGS_PATH: all-mpnet-base-v2
EMBEDDINGS_PATH: bge-small-en-v1.5

VECTORDB_TYPE: faiss
VECTORDB_PATH: vectordb/faiss
# VECTORDB_TYPE: chroma
# VECTORDB_PATH: vectordb/chroma

# USE_CTRANSFORMERS: True
# LLM_PATH: llama-2-7b-chat.Q4_K_M.gguf
# PROMPT_TYPE: llama2

# USE_CTRANSFORMERS: True
# LLM_PATH: mistral-7b-instruct-v0.2.Q4_K_M.gguf
# PROMPT_TYPE: mistral

# USE_CTRANSFORMERS: True
# LLM_PATH: zephyr-7b-beta.Q4_K_M.gguf
# PROMPT_TYPE: zephyr

# USE_CTRANSFORMERS: False
# LLM_PATH: gemma-2b-it-q4_k_m.gguf
# PROMPT_TYPE: gemma

USE_CTRANSFORMERS: False
LLM_PATH: Meta-Llama-3-8B-Instruct-Q4_K_M.gguf
PROMPT_TYPE: llama3

LLM_CONFIG:
  MAX_NEW_TOKENS: 512
  TEMPERATURE: 0.2
  REPETITION_PENALTY: 1.1
  CONTEXT_LENGTH: 4000

BASE_RETRIEVER_CONFIG:
  SEARCH_K: 4

# RERANKER_PATH: tart-full-flan-t5-xl
# RERANKER_TYPE: tart
RERANKER_PATH: bge-reranker-base
RERANKER_TYPE: bge

RERANK_RETRIEVER_CONFIG:
  SEARCH_K: 10
  TOP_N: 4

COMPRESSION_RETRIEVER_CONFIG:
  SEARCH_K: 10
  SIMILARITY_THRESHOLD: 0.5

PROPOSITIONIZER_PATH: propositionizer-wiki-flan-t5-large
PROPOSITIONIZER_CONFIG:
  CHUNK_SIZE: 1000
  CHUNK_OVERLAP: 0
