USE_TRACING: False

DEVICE: cpu  # used only by embeddings and propositionizer

TEXT_SPLIT_MODE: default  # default or propositionize
# propositionize uses propositionizer model

# MODELS_DIR: ./models
MODELS_DIR: /Users/user/Desktop/Dvorak/Work/models

EMBEDDINGS_PATH: bge-small-en-v1.5
# EMBEDDINGS_PATH: all-mpnet-base-v2
# EMBEDDINGS_PATH: all-MiniLM-L6-v2

VECTORDB_TYPE: faiss
VECTORDB:
  - PATH: ./vectordb/faiss
    NAME: document
    DESCRIPTION: Provides information about the document. Always use this first.

# LLM_TYPE: gguf
# LLM_PATH: llama-2-7b-chat.Q4_K_M.gguf
# PROMPT_TYPE: llama2

# LLM_TYPE: gguf
# LLM_PATH: mistral-7b-instruct-v0.2.Q4_K_M.gguf
# PROMPT_TYPE: mistral

# LLM_TYPE: gguf
# LLM_PATH: zephyr-7b-beta.Q4_K_M.gguf
# PROMPT_TYPE: zephyr

# LLM_TYPE: gguf
# LLM_PATH: gemma-2-2b-it-Q4_K_M.gguf
# PROMPT_TYPE: gemma

# LLM_TYPE: gguf
# LLM_PATH: Meta-Llama-3-8B-Instruct-Q4_K_M.gguf
# PROMPT_TYPE: llama3

# LLM_TYPE: gguf
# LLM_PATH: Phi-3-mini-4k-instruct-q4.gguf
# PROMPT_TYPE: phi3

# LLM_TYPE: gguf
# LLM_PATH: Meta-Llama-3.1-8B-Instruct-Q4_K_M.gguf
# PROMPT_TYPE: llama3

# LLM_TYPE: groq
# LLM_PATH: mixtral-8x7b-32768
# PROMPT_TYPE: mistral

LLM_TYPE: ollama
LLM_PATH: mymodel
PROMPT_TYPE: llama3

# LLM_TYPE: gemini
# LLM_PATH: gemini-1.5-flash
# PROMPT_TYPE: gemini

LLM_CONFIG:
  MAX_NEW_TOKENS: 512
  TEMPERATURE: 0.2
  REPETITION_PENALTY: 1.1
  CONTEXT_LENGTH: 4000

BASE_RETRIEVER_CONFIG:
  SEARCH_K: 4

# RERANKER_PATH: tart-full-flan-t5-xl
# RERANKER_TYPE: tart
RERANKER_PATH: bge-reranker-base
RERANKER_TYPE: bge

RERANK_RETRIEVER_CONFIG:
  SEARCH_K: 10
  TOP_N: 4

COMPRESSION_RETRIEVER_CONFIG:
  SEARCH_K: 10
  SIMILARITY_THRESHOLD: 0.5

PROPOSITIONIZER_PATH: propositionizer-wiki-flan-t5-large
PROPOSITIONIZER_CONFIG:
  CHUNK_SIZE: 1000
  CHUNK_OVERLAP: 0
